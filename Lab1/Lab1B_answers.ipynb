{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1051bede",
   "metadata": {},
   "source": [
    "# Lab 1B: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab690369",
   "metadata": {},
   "source": [
    "**WHAT** This nonmandatory lab consists of several programming and insight exercises/questions.\n",
    "\n",
    "**WHY** The exercises are meant to familiarize yourself with the basic concepts of data cleaning.\n",
    "\n",
    "**HOW** Follow the exercises in this notebook either on your own or with a fellow student. If you want to skip right to questions and exercises, find the $\\rightarrow$ symbol. \n",
    "\n",
    "$\\newcommand{\\q}[1]{\\rightarrow \\textbf{Question #1}}$\n",
    "$\\newcommand{\\ex}[1]{\\rightarrow \\textbf{Exercise #1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f5cbf",
   "metadata": {},
   "source": [
    "In this assignment, we will take a look at the LendingClub data set. This data corresponds to applications for loans issued in 2016. In order to use this data later for classification of loan applicants, we need to first explore and clean this data. \n",
    "Work your way through these exercises at your own pace and be sure to ask questions to the TA's when you don't understand something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53427678",
   "metadata": {},
   "source": [
    "## 1. Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954fe1a",
   "metadata": {},
   "source": [
    "We first start by reading the data from the LendingClub file provided in the assignemnt folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc40d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the raw data\n",
    "df = pd.read_csv('./LendingClub.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d2cf2",
   "metadata": {},
   "source": [
    "We then load the data dictionary. This dictionary provides a brief description of the features in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e106bd",
   "metadata": {},
   "source": [
    "$\\ex{1.1}$ Load the data dictionary from the csv file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a887cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = None\n",
    "# START ANSWER\n",
    "data_dictionary = pd.read_csv('./DataDictionary.csv')\n",
    "# END ANSWER\n",
    "\n",
    "data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45c0a6",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784151b",
   "metadata": {},
   "source": [
    "$\\ex{2.1}$ How many samples and features does the dataset contain?\n",
    "\n",
    "*Hint: Take a look at the pandas.DataFrame in the Pandas API reference scroll down to look at the list of attributes and methods, to familiarize yourself*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae242b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df.shape\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e84e5",
   "metadata": {},
   "source": [
    "$\\ex{2.2}$ Print the names of the features and their corresponding data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcdde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df.dtypes\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366c877",
   "metadata": {},
   "source": [
    "## 3. Removing unwanted observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4aa0ef",
   "metadata": {},
   "source": [
    "Lets take a look at **loan_status** feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cfad7",
   "metadata": {},
   "source": [
    "$\\ex{3.1}$ Find the possible values that the feature takes and their respective frequencies\n",
    "\n",
    "*Hint: Pandas objects have a method that can do this for you*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae40b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df['loan_status'].value_counts()\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9f9dc",
   "metadata": {},
   "source": [
    "This information can be visualized in the form of a histogram. Below we use the countplot function from the seaborn library to create this figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "g = sns.countplot(x=\"loan_status\",data=df,\n",
    "                  palette='hls')\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g.set_title(\"Loan Status\", fontsize=20)\n",
    "g.set_xlabel(\"Loan Status\", fontsize=15)\n",
    "g.set_ylabel(\"Loan Amount\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf64ea6",
   "metadata": {},
   "source": [
    "This data is going to be used to predict if a loan is going to be repaid or not based on the loan application. Therefore, we want to make sure that the samples that we use are relevant to making this prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b7923",
   "metadata": {},
   "source": [
    "The samples with the  **loan_status = \"Current\"** correspond to loans whiach are still active.\n",
    "These samples can be removed as they do not help in predicting if a loan has been repaid or not.\n",
    "\n",
    "$\\ex{3.2}$ Remove the samples that have **loan_status = Current** from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67295974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df = df[df['loan_status'] != 'Current']\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c73574",
   "metadata": {},
   "source": [
    "We want to do an analysis for the Pacific Coast states California, Oregon, and Washington (not DC!)\n",
    "\n",
    "$\\ex{3.3}$ Select the appropriate subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df = df[(df['addr_state'] == 'CA') | (df['addr_state'] == 'OR' ) | (df['addr_state'] =='WA')]\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31325bfe",
   "metadata": {},
   "source": [
    "## 4. Handling Duplicate Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec79db0",
   "metadata": {},
   "source": [
    "Next we want to make sure that there are no duplicate samples in the dataset.\n",
    "\n",
    "$\\ex{4.1}$ Find and print the duplicate observations in the dataset\n",
    "\n",
    "*Hint: Take a look at the pandas library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df[df.duplicated()]\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f97f8",
   "metadata": {},
   "source": [
    "$\\ex{4.2}$ Now remove the duplicates from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df = df.drop_duplicates()\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600d5ae",
   "metadata": {},
   "source": [
    "## 5. Detecting and Dealing with Highly Correlated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f0966",
   "metadata": {},
   "source": [
    "Features that are highly correlated to each other do not provide much additional information to the data but they do add complexity. \n",
    "\n",
    "$\\ex{5.1}$ Compute the correlation matrix for the numeric features and make a heatmap to visualize this.\n",
    "\n",
    "*Hint: Take a look at the heatmap function in the seaborn library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b61b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = None\n",
    "\n",
    "# START ANSWER\n",
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "# END ANSWER\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "# START ANSWER\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "# END ANSWER\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3f555",
   "metadata": {},
   "source": [
    "$\\ex{5.2}$ Can you identify the features that have a high correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177f01",
   "metadata": {},
   "source": [
    "To ensure that there is no redunt information we want to keep only one of the features in each pair of highly correlated features. \n",
    "\n",
    "$\\ex{5.3}$ Add code below to remove one of the features in each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b205aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "drop_list_correlated = [\"installment\",\"fico_range_high\"]\n",
    "df = df.drop(drop_list_correlated, axis=1)\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e363da",
   "metadata": {},
   "source": [
    "Above we dealt with the numeric features which had a high correlation. Let's take a look at the non-numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df.columns[df.dtypes == 'object']\n",
    "df[object_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae17d05",
   "metadata": {},
   "source": [
    "$\\ex{5.4}$ Can you identify the feature that can be removed without removing any information from the dataset (there is a feature providing redundant information)? Remove this feature from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53cb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the redundant non-numeric feature\n",
    "# START ANSWER\n",
    "df = df.drop(['grade'], axis =1)\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58335dfd",
   "metadata": {},
   "source": [
    "## 6. Dealing with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96697cb7",
   "metadata": {},
   "source": [
    "Another major aspect of data cleaning is handling missing values. There are several ways in which this can be done. We will explore a few different scenarios below.\n",
    "\n",
    "$\\ex{6.1}$ Find the number of null values in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a857a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "null_count = df.isnull().sum()\n",
    "null_count\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3453bc9",
   "metadata": {},
   "source": [
    "Features that have a high percentage of NaN values are not reliable for prediction. These features are usually removed from the dataset.\n",
    "\n",
    "$\\ex{6.2}$ Remove the feature that has more than 25% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df = df.drop(['settlement_amount'], axis=1)\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703486ef",
   "metadata": {},
   "source": [
    "First we inspect the categorical feature **title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c11050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235c2f2",
   "metadata": {},
   "source": [
    "The most appropriate value to replace the NaNs with for title is Other.\n",
    "\n",
    "$\\ex{6.3}$  Raplace the NaN values corresponding to the feature **title** with \"Other\"\n",
    "\n",
    "*Hint: take a look at the fillna() method in pandas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c521c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df['title'].fillna(value=\"Other\", inplace=True)\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936155dc",
   "metadata": {},
   "source": [
    "Now lets take a look at the **dti** feature. Since only 1 sample has a NaN value for this feature, we can handle them by removing this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f9a6a",
   "metadata": {},
   "source": [
    "$\\ex{6.4}$ Remove the samples with NaN values for **dti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df.dropna(subset=[\"dti\"], inplace=True)\n",
    "# END ANSWER\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26744b1d",
   "metadata": {},
   "source": [
    "The final feature with missing values is **bc_util**. This is a numeric feature that has a significant number of NaN values. In order to handle this, we will replace this value with an appropriate metric.\n",
    "\n",
    "$\\ex{6.5}$ Can you think of some apppropriate value that could be used to replace the missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b9224",
   "metadata": {},
   "source": [
    "$\\ex{6.6}$ Find the mean, median and standard deviation of the values of this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = None\n",
    "median_value = None\n",
    "standard_deviation = None\n",
    "\n",
    "# START ANSWER\n",
    "mean_value = df['bc_util'].mean()\n",
    "median_value = df['bc_util'].median()\n",
    "standard_deviation = df['bc_util'].std()\n",
    "# END ANSWER\n",
    "\n",
    "print(\"Median:\", median_value)\n",
    "print(\"Mean:\", mean_value)\n",
    "print(\"Standard Deviation:\", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42757f1",
   "metadata": {},
   "source": [
    "$\\ex{6.7}$ Plot the histogram for this feature.\n",
    "\n",
    "*Hint: You can use the plot.hist() method in pandas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f201d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df['bc_util'].plot.hist(bins=200)\n",
    "plt.show()\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208f460",
   "metadata": {},
   "source": [
    "$\\ex{6.8}$ Replace the missing values with a suitable value. What value did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7806f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "df['bc_util'].fillna(value=mean_value, inplace=True)\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1547fc",
   "metadata": {},
   "source": [
    "## 7. Removing features with little predictive value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e896d",
   "metadata": {},
   "source": [
    "Sometimes, based on the problem setting, some features do not provide helpful information in terms of prediction. In these cases the features are removed in order to simplify the dataset.\n",
    "\n",
    "$\\ex{7.1}$ Can you identify 2 least useful features in this case? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
