{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d159f5-f16d-4c63-a3d3-2378e0120283",
   "metadata": {},
   "source": [
    "# **Lab 1A: Training, validation, model selection, and testing**\n",
    "## The Salary versus Age example from Hull Section 1.4, analysed with Python\n",
    "Section 1.4 explains some of the most important principles of machine learning. Sticking to these principles will get you well on your way to producing valid and reliable results with your machine learning applications. The idea of this lab is to try to reproduce the results in Hull Section 1.4, as exactly as possible. \n",
    "\n",
    "This notebook is partially complete and you are to complete and correct things where appropriate. There are also some questions included, for you to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5c3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as clrs\n",
    "\n",
    "np.set_printoptions(precision=3)  # print results with 3 decimals behind the decimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f566b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529426c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as clrs\n",
    "\n",
    "np.set_printoptions(precision=3)  # print results with 3 decimals behind the decimal point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a83a9f",
   "metadata": {},
   "source": [
    "## 1. Loading and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8558a5e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Salary_vs_Age.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalary_vs_Age.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Check the data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(raw\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# check dimensions\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Salary_vs_Age.csv'"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "raw = pd.read_csv('Salary_vs_Age.csv')\n",
    "# Check the data\n",
    "print(raw.shape) # check dimensions\n",
    "raw.head(10)    # check against Hull Table 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b74a9b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "We split the data into a training, validation, and test set as needed for the analysis with our regression models that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_array = np.array(raw) # convert dataframe into numpy array \n",
    "training_data = raw_array[:10, :] # First ten instances will form the training data set (as in Table 1.1).\n",
    "validation_data = raw_array[10:20, :] # The next ten instances will form the validation data (Table 1.2).\n",
    "test_data = raw_array[20:, :] # The final ten instances will form the test set (Table 1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9d99d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "**Question 1** What is the purpose for each of the sets we make?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44d570",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "Write your answer here \n",
    "    \n",
    "[//]: # (START ANSWER)\n",
    "The training set is used to determine the parameters of the models that are under consideration. The validation set is used to determine how well each of the models generalizes to a different data set. The test set is held back to provide a measure of the accuracy of the chosen model. This enables us to test out-of-sample wherever this is prudent.\n",
    "\n",
    "[//]: # (END ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f740e9-2404-4e9f-a37f-bbc60386be06",
   "metadata": {},
   "source": [
    "## 2. Plotting Figure 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119cd9e8",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "We will now plot the training data; a plot for has already been given, but requires some sprucing up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ddd77-9f39-4959-b59a-272af193b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244418d3-d178-408f-8ace-d4d5c52ff438",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_age, train_sal = training_data[:,0], training_data[:,1]\n",
    "np.vstack([train_age, train_sal]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c9025-3b0a-45fb-9562-8d86cb306f5a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "Find out what type of object `ax` is and search the Matplotlib API reference for 'matplotlib.axes.Axes.set' to find out how to\n",
    "> * label the x- and y-axis of the plot;\n",
    "> * add a title to the plot;\n",
    "> * change the axes ranges;\n",
    "\n",
    "Then add commands to make the figure below look exactly like Figure 1.2 in Hull. We have already passed an appropriate figure size argument to `subplots()` so that the proportions more or less match those of Figure 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure \n",
    "fig, ax = plt.subplots(figsize = (8,5))  \n",
    "\n",
    "# START ANSWER\n",
    "ax.set_xlim([20, 70])  # set limit as in Figure 1.2\n",
    "ax.set_ylim([0, 350000])\n",
    "# END ANSWER \n",
    "\n",
    "# Plot the training data \n",
    "ax.scatter(train_age, train_sal)\n",
    "\n",
    "# START ANSWER\n",
    "ax.set_ylabel('Salary ($)')\n",
    "ax.set_xlabel('Age (years)')\n",
    "ax.set_title('Figure 1.2  Scatter plot of the training data set')\n",
    "# END ANSWER\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418deff-4d78-4cf1-bc10-01fdc8f323e2",
   "metadata": {},
   "source": [
    "## 3. Fitting a fifth degree polynomial to the training data\n",
    "Below we have used Numpy's `polyfit` and `poly1d` because it seems an accessible route for this first lab; look them up in the Numpy's API Reference. At the end, we will redo some of the analyses using Scikit-learn methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e48d3-6c01-4685-a07f-2eeac3cd1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef5 = np.polyfit(train_age, train_sal, 5)  # coefficients of LS fit, highest order first\n",
    "for i in range(6):\n",
    "    print(f\"b{i}= {coef5[5-i]:+10.3e}\") \n",
    "print(\"\")\n",
    "p5 = np.poly1d(coef5)  # creates a polynomial function with coefficients from coef5\n",
    "print(np.vstack((train_age, train_sal, p5(train_age))).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69633ff4-c610-4367-9e13-d0ae9eac9782",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "**Question 2.** What do you notice about the fitted coefficients? Can you explain (some of) it?\n",
    "\n",
    "**Question 3.** What's in the matrix that is printed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c607c9b-f974-43f6-aa45-ec0943f21511",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "    \n",
    "Write your answer here \n",
    "\n",
    "[//]: # (START ANSWER)\n",
    "They alternate in sign, so the fitted values are sums of positive and negative values and these values are **big** when you compare them to the order of magnitude of the salaries; this is not a good sign, hints at numerical instability. The size of the coefficients decreases; this probably has to do with the fact that x^n increase rapidly for x in our age-range, and ever more rapidly as n is bigger, the decreasing coefficient sizes compensate for that. To avoid this one often does *feature scaling*; we'll get to that in Chapter 2.\n",
    "\n",
    "[//]: # (END ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5bfa8-fa23-4285-80e3-ae6202abc34b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "Compute the residuals for this model fit as well as the root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95cf64-6469-4ccf-93bd-334961684785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train5_res = None\n",
    "train5_rmse = None\n",
    "\n",
    "# START ANSWER\n",
    "train5_res = p5(train_age) - train_sal\n",
    "train5_rmse = np.std(train5_res)\n",
    "# END ANSWER\n",
    "print(f\"rmse = {train5_rmse:5.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac50b9-74e8-44d6-b8e5-d33e7d6b5599",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "\n",
    "This is not the same as the 12902 in Hull which is a factor sqrt(10/9) bigger. Look up `numpy.std` and play with `ddof` until you get it: it seems that Hull uses *root mean squared error* and *standard deviation of the errors* interchangeably, though this is not correct.\n",
    "\n",
    "Below add commands to make the figure look exactly like Figure 1.3 in Hull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f51f0-5b92-4d0f-aa9c-189b70f02d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure that looks exactly like Hull Figure 1.3\n",
    "fig, ax = plt.subplots(figsize = [8,5])  \n",
    "ax.scatter(train_age, train_sal)\n",
    "age_range = np.linspace(np.min(train_age), np.max(train_age), 1000)\n",
    "ax.plot(age_range, p5(age_range), color='red', label='Degree 5 polynomial fit')\n",
    "\n",
    "# START ANSWER\n",
    "ax.set_xlim([20, 70])  # set limit as in Figure 1.2\n",
    "ax.set_ylim([0, 350000])\n",
    "\n",
    "# Add labels and a legend\n",
    "ax.set_ylabel('Salary ($)')\n",
    "ax.set_xlabel('Age (years)')\n",
    "ax.set_title(\"Figure 1.3  Result of fitting a polynomial of degree 5\")\n",
    "ax.legend()\n",
    "# END ANSWER\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb10ba-7a1f-46e5-a334-efa501e47855",
   "metadata": {},
   "source": [
    "## 4. Plotting Figure 1.4 (the validation data) and adding the fitted curve\n",
    "Use the validation data to (exactly) reproduce Hull Figure 1.4. Add to the figure the fitted fifth order polynomial we just determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee5738-c730-428c-8cf0-3c425f255d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_age, val_sal = validation_data[:,0], validation_data[:,1]\n",
    "\n",
    "# Create figure that looks (almost) exactly like Hull Figure 1.4\n",
    "fig, ax = plt.subplots(figsize = [8,5])  \n",
    "ax.scatter(val_age, val_sal)\n",
    "\n",
    "# START ANSWER\n",
    "ax.set_xlim([20, 70])  # set limit as in Figure 1.2\n",
    "ax.set_ylim([0, 350000])\n",
    "ax.set_ylabel('Salary ($)')\n",
    "ax.set_xlabel('Age (years)')\n",
    "ax.set_title(\"Figure 1.4  Scatter plot for validation data in Table 1.2\")\n",
    "# END ANSWER\n",
    "\n",
    "# START ANSWER\n",
    "age_range = np.linspace(np.min(train_age), np.max(train_age), 1000)\n",
    "ax.plot(age_range, p5(age_range), color='red', label='Degree 5 polynomial fit')\n",
    "ax.legend()\n",
    "# END ANSWER\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034e494-c5e7-4e59-a143-0c5f3b39d67c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "\n",
    "**Question 4.** What is your conclusion about the fitted model, judging by the plot you just made?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca988290",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "Write your answer here \n",
    "    \n",
    "[//]: # (START ANSWER)\n",
    "A curve fitting the validation data would not be so wiggly, but a smooth upward sloping concave curve.\n",
    "\n",
    "[//]: # (END ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0d6c3-7a31-4c98-ad29-9f0f79dcf7be",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "Compute the residuals for the validation data and the fitted model and then the root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b19627-3da8-4191-a0bd-f83ce2a200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val5_res = None\n",
    "val5_rmse = None\n",
    "\n",
    "# START ANSWER\n",
    "val5_res = p5(val_age) - val_sal\n",
    "val5_rmse = np.std(val5_res, ddof = 1)\n",
    "# END ANSWER\n",
    "\n",
    "print(f\"rmse = {val5_rmse:5.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47591b19-b8e8-49db-b5b7-f69782827cb5",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "**Question 5.** Are these results signs of overfitting or underfitting? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377fa5c9-1820-470d-ada4-8240385fde8c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "    \n",
    "Write your answer here \n",
    "\n",
    "[//]: # (START ANSWER)\n",
    "The rmse of the validation data is about three times as big as for the training data: the model is *over*fit, tailored very much to the training data. The quirks of the training data are followed and show up as extra variance when checking the fit with new data: the model does not generalize well.\n",
    "\n",
    "[//]: # (END ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d77aa-90f9-4cdb-9bc5-28d558f14828",
   "metadata": {},
   "source": [
    "## 5. Fit a quadratic model to the training data and reproduce Figure 1.5\n",
    "You can do that on your own...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13267e51-fa5b-4645-84a5-5ec31a72abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "coef2 = np.polyfit(train_age, train_sal, 2)  # coefficients of LS fit, highest order first\n",
    "for i in range(3):\n",
    "    print(f\"b{2-i}= {coef2[i]: 10.3e}\") \n",
    "print(\"\")\n",
    "p2 = np.poly1d(coef2)  # creates a polynomial function with coefficients from coef2\n",
    "print(np.vstack((train_age, train_sal, p2(train_age))).transpose())\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b16b8-395c-42a0-b440-a69f05a8e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_res = None\n",
    "train2_rmse = None\n",
    "\n",
    "# START ANSWER\n",
    "train2_res = p2(train_age) - train_sal\n",
    "train2_rmse = np.std(train2_res, ddof = 1)  \n",
    "# END ANSWER\n",
    "print(f\"rmse training set: {train2_rmse:5.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249db2a4-aab1-44a0-b4b4-54a80bb36cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val2_res = None\n",
    "val2_rmse = None\n",
    "\n",
    "# START ANSWER\n",
    "val2_res = p2(val_age) - val_sal\n",
    "val2_rmse = np.std(val2_res, ddof = 1)\n",
    "# END ANSWER\n",
    "print(f\"rmse validation set: {val2_rmse:5.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc01f6-4d72-4a41-8ebf-a8cc7c49da31",
   "metadata": {},
   "source": [
    "## 6. Fit a linear model to the training data and reproduce Figure 1.6\n",
    "Just go ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb95bed-6837-41c3-af38-7905eba0ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "coef1 = np.polyfit(train_age, train_sal, 1)  # coefficients of LS fit, highest order first\n",
    "for i in range(2):\n",
    "    print(f\"b{1-i}= {coef1[i]:+10.3e}\") \n",
    "print(\"\")\n",
    "p1 = np.poly1d(coef1)  # creates a polynomial function with coefficients from coef1\n",
    "print(np.vstack((train_age, train_sal, p1(train_age))).transpose())\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c28431-30af-4d47-af81-1a0cda20510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_res = None\n",
    "train1_rmse = None\n",
    "\n",
    "# START ANSWER\n",
    "train1_res = p1(train_age) - train_sal\n",
    "train1_rmse = np.std(train1_res, ddof = 1)  \n",
    "# END ANSWER\n",
    "print(f\"rmse training set  : {train1_rmse:5.0f}\")\n",
    "\n",
    "val1_res = None\n",
    "val1_rmse = None\n",
    "\n",
    "# START ANSWER\n",
    "val1_res = p1(val_age) - val_sal\n",
    "val1_rmse = np.std(val1_res, ddof = 1)\n",
    "# END ANSWER\n",
    "print(f\"rmse validation set: {val1_rmse:5.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c88db-cc6e-4d65-8356-053caf5a8d3c",
   "metadata": {},
   "source": [
    "## 7. Compute root mean square errors and reproduce Table 1.3\n",
    "Go ahead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a414d-0c43-4878-a37e-bb18d8389404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the table:\n",
    "# START ANSWER\n",
    "train5_rmse = np.std(train5_res, ddof = 1) # making sure\n",
    "train_rmse = [train5_rmse, train2_rmse, train1_rmse]\n",
    "validation_rmse = [val5_rmse, val2_rmse, val1_rmse]\n",
    "\n",
    "columns = [\"Polynomial degree 5\", \"Quadratic model\", \"Linear model\"]\n",
    "table = pd.DataFrame(data=[train_rmse , validation_rmse] ,columns = columns, index = ['training set rmse', \"validation set rmse\"])\n",
    "table.round(decimals=0)\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68742b5-5bd6-45b6-82eb-8c7a42c46045",
   "metadata": {},
   "source": [
    "## 8. Redo all regression models and a bit more using Scikit-learn\n",
    "What we did above followed the exposition of Section 1.4. Once you have overview, there may be a more efficient way to get all the results. You may already have done some things more efficiently than in the answers above.\n",
    "Below we use Scikit-learn tools  (in Python you write `sklearn` for Scikit-learn):\n",
    " + `sklearn.linear_model.LinearRegression`, and\n",
    " + `sklearn.preprocessing.PolynomialFeatures`\n",
    "\n",
    "Check out what [PolynomialFeatures](https://scikit-learn.org/stable/modules/preprocessing.html#generating-polynomial-features) does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea7529",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "We will now create five regression models from degree 1 to 5. Each model will be trained on the training data and then tested on the validation data. We will store the rmse of the training and validation data in arrays. Complete the code block by calculating the RMSE for the training set and validation set and storing it in the defined arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00995ee-fca3-4b8a-9bcd-f6cf9dd2d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_train, y_train = training_data[:, 0], training_data[:, 1] \n",
    "X_val, y_val = validation_data[:, 0], validation_data[:, 1]\n",
    "X_test, y_test = test_data[:, 0], test_data[:, 1] \n",
    "\n",
    "# Degrees \n",
    "degrees = [1,2,3,4,5] \n",
    "colors = ['green', 'blue', 'red', 'purple', 'magenta']\n",
    "train_rmse = [] \n",
    "validation_rmse = [] \n",
    "\n",
    "for i in degrees: \n",
    "    plt.subplots(figsize = [8,5])\n",
    "    plt.scatter(X_train, y_train, label = 'Training data')\n",
    "    plt.scatter(X_val, y_val, color = 'red', marker = '^', label = 'Validation data')\n",
    "\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "    X_val_poly = poly.fit_transform(X_val.reshape(-1, 1))\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train) \n",
    "    \n",
    "    train_predictions = model.predict(X_train_poly) \n",
    "    val_predictions = model.predict(X_val_poly) \n",
    "    \n",
    "    # START ANSWER \n",
    "    train_rmse.append(np.std(train_predictions - y_train, ddof=1))\n",
    "    validation_rmse.append(np.std(val_predictions - y_val, ddof=1))\n",
    "    # END ANSWER\n",
    "    \n",
    "    \n",
    "    sorted_indices = np.argsort(X_train)\n",
    "    X_test_polynomial = X_train[sorted_indices]\n",
    "    predictions = train_predictions[sorted_indices]\n",
    "    plt.plot(X_test_polynomial, predictions, color=colors[i-1], label=f\"Degree {i}\")\n",
    "\n",
    "    # Add labels and a legend\n",
    "    plt.xlabel('Age (years)')\n",
    "    plt.ylabel('Salary ($)')\n",
    "    plt.title(f\"Regression model for degree {i}\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3b68a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "\n",
    "Plot the training rmse and validation rmse on the same graph for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843eb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "plt.plot(degrees, train_rmse, label=\"Training set RMSE\")\n",
    "plt.scatter(degrees, train_rmse)\n",
    "plt.scatter(degrees, validation_rmse)\n",
    "plt.plot(degrees, validation_rmse,linestyle='dashed', label = \"Validation set RMSE\")\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title(\"RMSE of train and validation set of regression models with varying degrees\")\n",
    "plt.xticks(ticks=[1,2,3,4,5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2aa1d1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "Create a table showing the rmse of the training and validation sets of the different regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ad839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER \n",
    "columns = [\"Linear model\" , \"Quadratic model\", \"Polynomial degree 3\", \"Polynomoial degree 4\", \"Polynomial degree 5\"]\n",
    "table = pd.DataFrame(data=[train_rmse , validation_rmse] ,columns = columns, index = ['training set RMSE', \"test set RMSE\"])\n",
    "table.round(decimals=0)\n",
    "# END ANSWER "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285b48e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "\n",
    "**Question 6.** Comment on things you notice about the graphs and  the table. Rank the models in terms of performace. Which model displays signs of overfitting or underfitting? Does the best fit model generalize well from the training set to the validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf43ed4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "Write your answer here \n",
    "\n",
    "    \n",
    "[//]: # (START ANSWER)\n",
    "The linear model performs quite poorly for the training set and for the validation set showing that the model is quite underfitted. The quadratic model is the best model as both training and validation error is low. Degree 3 is the second best model as it's validation error is slightly higher than the quadratic model which suggests a slight overfit (remember: each data set has size 10, so don't expect to make firm conclusions here). Degree 4 and 5 we see strong signs of overfitting as the validation error is much larger than the train error.  \n",
    "\n",
    "[//]: # (END ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf91f37",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "Determine the final prediction rmse on the **test** set using the best determined model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d41a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER \n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "X_poly_test = poly.fit_transform(X_test.reshape(-1, 1))\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y_train)\n",
    "predictions = model.predict(X_poly_test)\n",
    "rmse = np.std(predictions - y_test, ddof=1)  \n",
    "\n",
    "print(f\"RMSE of best model: {rmse:6.0f}\")\n",
    "# END ANSWER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb353b4-89fc-422c-b0fe-e949fc35aea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
