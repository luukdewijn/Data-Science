{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 5A: Classification Trees**\n",
    "\n",
    "**WHAT** This nonmandatory lab consists of several programming and insight exercises/questions.\n",
    "\n",
    "**WHY** The exercises are meant to get some experience fitting Classification Trees.\n",
    "\n",
    "**HOW** Follow the exercises in this notebook either on your own or with a fellow student. Work your way through these exercises at your own pace and be sure to ask questions to the TA's when you don't understand something.\n",
    "\n",
    "$\\newcommand{\\q}[1]{\\rightarrow \\textbf{Question #1}.}$\n",
    "$\\newcommand{\\ex}[1]{\\rightarrow \\textbf{Exercise #1}.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz, export_text\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('lendingclub_traindata.xlsx')\n",
    "validation = pd.read_excel('lendingclub_valdata.xlsx')\n",
    "test = pd.read_excel('lendingclub_testdata.xlsx')\n",
    "# 1 = good, 0 = default\n",
    "print(train.head())\n",
    "print(\"----------------------\")\n",
    "print(validation.head())\n",
    "print(\"----------------------\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove target column to create feature only dataset\n",
    "X_train = train.drop('loan_status',axis=1)\n",
    "X_val=validation.drop('loan_status',axis=1)\n",
    "X_test=test.drop('loan_status',axis=1)\n",
    "\n",
    "# store target column\n",
    "y_train = train['loan_status']\n",
    "y_val=validation['loan_status']\n",
    "y_test=test['loan_status']\n",
    "\n",
    "colnames = list(X_train.columns)\n",
    "print(\"Features:\", *colnames, sep=\"  \")\n",
    "print(\"Matrix dimensions: \", X_train.shape, y_train.shape, X_val.shape,y_val.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitting Decision Trees, finding a good one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy',max_depth=4,min_samples_split=1000,min_samples_leaf=200,random_state=0)\n",
    "clf = clf.fit(X_train,y_train)\n",
    "fig, ax = plt.subplots(figsize=(40, 30))\n",
    "plot_tree(clf, filled=True, feature_names=colnames, proportion=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_avg_loglik(y, probs):\n",
    "    # Preconditions:\n",
    "    # y: ndarray of 0/1\n",
    "    # probs: two-column ndarray, rows contain [P(Y=0),P(Y=1)]\n",
    "    return np.average(-np.log(y * probs[:,1] + (1-y) * probs[:,0]))\n",
    "    \n",
    "\n",
    "# prob_train, prob_val, and prob_test are the predicted probabilities for the training,\n",
    "# validation, and test set, using the fitted logistic regression model\n",
    "\n",
    "prob_train = clf.predict_proba(X_train)\n",
    "prob_val = clf.predict_proba(X_val)\n",
    "prob_test = clf.predict_proba(X_test)\n",
    "\n",
    "print(prob_train)\n",
    "\n",
    "# Calculate the negative of the average loglikelihood for training, validation, and test set\n",
    "\n",
    "cost_func_train_minimum = neg_avg_loglik(y_train, prob_train)\n",
    "cost_func_val = neg_avg_loglik(y_val, prob_val)\n",
    "cost_func_test = neg_avg_loglik(y_test, prob_test)\n",
    "\n",
    "print('\\nCost function value overview:')\n",
    "print(f'        value for training set   = {cost_func_train_minimum:10.8f}')\n",
    "print(\"From this trained model:\")\n",
    "print(f'        value for validation set = {cost_func_val:10.8f}')\n",
    "print(f'              value for test set = {cost_func_test:10.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "$\\q{1}$  Fit at least five more trees by varying arguments in the `DecisionTreeClassifier`-call:\n",
    "1. criterion (try 'gini' at least once),\n",
    "2. max_depth,\n",
    "3. min_samples_split,\n",
    "4. min_samples_leaf.\n",
    "\n",
    "Use negative average loglikelhood criterion and the validation set to choose the best tree. Make a table with the four argument values in columns 1 to 4, supplemented with cost function scores for the training and validation sets.\n",
    "\n",
    "You might use the test set to determine a score for the best model.\n",
    "Assign the best model to `clf` below, so the rest of the code produces what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating the best tree and finding the most profitable threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = [.75, .80, .85]\n",
    "results = pd.DataFrame(columns=[\"THRESHOLD\", \"accuracy\", \"true pos rate\", \"true neg rate\", \"false pos rate\", \"precision\", \"f-score\"]) # df to store results\n",
    "results['THRESHOLD'] = THRESHOLD                                                                           # threshold column\n",
    "Q = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "j = 0                                                                                                      \n",
    "for i in THRESHOLD:                                                                                        # iterate over each threshold        \n",
    "                                                 # fit data to model\n",
    "    preds = np.where(Q>i, 1, 0)                  # if prob > threshold, predict 1\n",
    "    \n",
    "    cm = (confusion_matrix(y_test, preds,labels=[1, 0], sample_weight=None)/X_test.shape[0])*100 \n",
    "    # confusion matrix (in percentage)\n",
    "    \n",
    "    print('Confusion matrix for threshold =',i)\n",
    "    print(cm)\n",
    "    print(' ')      \n",
    "    \n",
    "    TP = cm[0][0]                                                                                          # True Positives\n",
    "    FN = cm[0][1]                                                                                          # False Positives\n",
    "    FP = cm[1][0]                                                                                          # True Negatives\n",
    "    TN = cm[1][1]                                                                                          # False Negatives\n",
    "        \n",
    "    results.iloc[j,1] = accuracy_score(y_test, preds) \n",
    "    results.iloc[j,2] = recall_score(y_test, preds)\n",
    "    results.iloc[j,3] = TN/(FP+TN)                                                                         # True negative rate\n",
    "    results.iloc[j,4] = FP/(FP+TN)                                                                         # False positive rate\n",
    "    results.iloc[j,5] = precision_score(y_test, preds)\n",
    "    results.iloc[j,6] = f1_score(y_test, preds)\n",
    "   \n",
    "    j += 1\n",
    "\n",
    "print('ALL METRICS')\n",
    "# print(results.T.to_string(header=False))\n",
    "results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure(figsize=(8,6))      # format the plot size\n",
    "lw = 1.5\n",
    "plt.plot(fpr, tpr, color='darkorange', marker='.',\n",
    "         lw=lw, label='Decision Tree (AUC = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--',\n",
    "         label='Random Prediction (AUC = 0.5)' )\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "$\\q{2}$ Suppose the population of lenders actually consists of 90% \"good\" and 10% \"bad\" lenders. Suppose, the profit from a good loan is $V$ and the loss from a bad loan is $4V$. Look at $\\S 3.11$ and explain why the criterion to optimize is:\n",
    "V x TPR(Z) x 0.9 - 4 V x FPR(Z) x 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ffa500\">\n",
    "    \n",
    "Write your answer in this colored box:\n",
    "\n",
    "[//]: # (START ANSWER)\n",
    "[//]: # (END ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\">\n",
    "    \n",
    "$\\q{3}$  Which of the three threshold values results in the highest expected profit per loan evaluated? And huw much is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START ANSWER\n",
    "# END ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
